{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9137bb68",
   "metadata": {},
   "source": [
    "# Deep Learning with RNNs (Sequence Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa37699",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de68508",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is for applying Hugging Face to various transformer models -  its library downloads pretrained models for Natural Language Understanding (NLU) tasks, such as analyzing the sentiment of a text, and Natural Language Generation (NLG), such as completing a prompt with new text or translating in another language.\n",
    "\n",
    "Transformers provides general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet…) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between Jax, PyTorch and TensorFlow.\n",
    "\n",
    "In this notebook, it will implement fill-mask model to generate inputs and labels from texts, question answering model can be used for answering questions, summarization is to summarize a document or an article into a shorter text, text generation to create a coherent portion of text that is a continuation from the given contextm amd some classification model is for classifying the texts, tokens and features. The sentences similarity and translation are operating below as well.\n",
    "\n",
    "With each transformer model, at least one example will be given in the loaded models to show its results meet our task requirements or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665dfc92",
   "metadata": {},
   "source": [
    "Adapted from Transformers Model in [Hugging Face](https://huggingface.co/), and [HuggingFace Crash Course](https://www.youtube.com/watch?v=GSt00_-0ncQ) in Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e38285",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "* [Installation](#installation)\n",
    "\n",
    "\n",
    "* [Implementation](#implementation)\n",
    "\n",
    "   \n",
    "   * [Fill-Mask](#fill-mask)\n",
    "   \n",
    "       * [Explanation](#fm_explanation)\n",
    "       \n",
    "    \n",
    "   * [Question Answering](#question_answering)\n",
    "       \n",
    "       * [Explanation](#qa_explanation)\n",
    "       \n",
    "    \n",
    "   * [Summarization](#summarization)\n",
    "   \n",
    "       * [Explanation](#sm_explanation)\n",
    "       \n",
    "    \n",
    "   * [Text Classification](#text_classification)\n",
    "       \n",
    "       * [Explanation](#tc_explanation)\n",
    "       \n",
    "    \n",
    "   * [Text Generation](#text_generation)\n",
    "   \n",
    "       * [Explanation](#tg_explanation)\n",
    "       \n",
    "    \n",
    "   * [Text2Text Generation](#text2text_generation)\n",
    "   \n",
    "       * [Explanation](#t2t_explanation)\n",
    "       \n",
    "    \n",
    "   * [Token Classification](#token_classification)\n",
    "   \n",
    "       * [Explanation](#tkc_explanation)\n",
    "       \n",
    "    \n",
    "   * [Translation](#translation)\n",
    "   \n",
    "       * [Explanation](#trans_explanation)\n",
    "       \n",
    "    \n",
    "   * [Zero-Shot Classification](#zero-shot_classification)\n",
    "   \n",
    "       * [Explanation](#zs_explanation)\n",
    "       \n",
    "    \n",
    "   * [Sentence Similarity](#sentence_similarity)\n",
    "   \n",
    "       * [Explanation](#ss_explanation)\n",
    "       \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a6486",
   "metadata": {},
   "source": [
    "## 0. Installing Transformers and Importing Dependencies <a class=\"anchor\" id=\"installation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b66260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: filelock in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: requests in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: six in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfade3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a10848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43935d",
   "metadata": {},
   "source": [
    "## 1. Loading Hugging Face Models  <a class=\"anchor\" id=\"implementation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756e5ec",
   "metadata": {},
   "source": [
    "### 1-1. Load Fill-Mask Pipeline  <a class=\"anchor\" id=\"fill-mask\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fbeaa",
   "metadata": {},
   "source": [
    "Fill-Mask (10 Points)\n",
    "\n",
    "Run a [Fill-Mask](https://huggingface.co/models?pipeline_tag=fill-mask&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7299dbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81a627dbbcd481d9f70704331fb5591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc979fd171424bc385c7ba23e428ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a123f273cdc4c5abea51640b6965605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eca77b13a1147768fe43c4c937b7bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a283d40d038d494d99391d45ef7932b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "237a36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Excuse me sir, do you speak [MASK]?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e476a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'excuse me sir, do you speak english?',\n",
       "  'score': 0.7569448947906494,\n",
       "  'token': 2394,\n",
       "  'token_str': 'english'},\n",
       " {'sequence': 'excuse me sir, do you speak french?',\n",
       "  'score': 0.09214285016059875,\n",
       "  'token': 2413,\n",
       "  'token_str': 'french'},\n",
       " {'sequence': 'excuse me sir, do you speak italian?',\n",
       "  'score': 0.02898499369621277,\n",
       "  'token': 3059,\n",
       "  'token_str': 'italian'},\n",
       " {'sequence': 'excuse me sir, do you speak spanish?',\n",
       "  'score': 0.026109404861927032,\n",
       "  'token': 3009,\n",
       "  'token_str': 'spanish'},\n",
       " {'sequence': 'excuse me sir, do you speak german?',\n",
       "  'score': 0.02030790224671364,\n",
       "  'token': 2446,\n",
       "  'token_str': 'german'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de6a3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"I'm a student from [MASK] University.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd5189aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': \"i'm a student from the university.\",\n",
       "  'score': 0.22754523158073425,\n",
       "  'token': 1996,\n",
       "  'token_str': 'the'},\n",
       " {'sequence': \"i'm a student from northwestern university.\",\n",
       "  'score': 0.0344078503549099,\n",
       "  'token': 7855,\n",
       "  'token_str': 'northwestern'},\n",
       " {'sequence': \"i'm a student from stanford university.\",\n",
       "  'score': 0.032529089599847794,\n",
       "  'token': 8422,\n",
       "  'token_str': 'stanford'},\n",
       " {'sequence': \"i'm a student from duke university.\",\n",
       "  'score': 0.03200804069638252,\n",
       "  'token': 3804,\n",
       "  'token_str': 'duke'},\n",
       " {'sequence': \"i'm a student from columbia university.\",\n",
       "  'score': 0.031160930171608925,\n",
       "  'token': 3996,\n",
       "  'token_str': 'columbia'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4a9d9",
   "metadata": {},
   "source": [
    "### Explanation - Fill-Mask <a class=\"anchor\" id=\"fm_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1ffdd",
   "metadata": {},
   "source": [
    "It was a pretrained model on English language using a masked language modeling (MLM). \n",
    "\n",
    "Masked language modeling (MLM): taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378c591",
   "metadata": {},
   "source": [
    "The model learns an inner representation of the English language that can then be used to extract features useful for downstream tasks, and can train a standard classifier using the features produced by the BERT model as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9329ac26",
   "metadata": {},
   "source": [
    "From the result we got, the model can analyze the masked token and their accuracy score. We can see when I set a sentence whose marked token is obviously language. The model perfectly gives me results of different languages. Then I set another example which is the name of the university is marked, and we check their results. The first result is the definite article, this one is obviously not the answer I expected. However, it makes sense. The rest of the results are great to complete the sentence and match the meaning. Generally speaking, the words predicted by the fill-mask model are quite accurate, and basically have the meaning of comparing the words before and after. But it can't give a complete text, it can only give an accuracy analysis in the filling of the blanks of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d197a",
   "metadata": {},
   "source": [
    "### 1-2. Load Question Answering Pipeline  <a class=\"anchor\" id=\"question_answering\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58d176",
   "metadata": {},
   "source": [
    "Question Answering (10 Points)\n",
    "\n",
    "Run a [Question Answering](https://huggingface.co/models?pipeline_tag=question-answering&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8778274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52691cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95e4e650ccc4079b5f04b6880a53d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660dc1624892415aa166de262a4b0ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ef2ec8f78243508176bae0745335e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c89b634216147258470ec7885619c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac0de2a091e4be9a71c5850d2cc8d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9777289032936096,\n",
       " 'start': 78,\n",
       " 'end': 105,\n",
       " 'answer': 'Jax, PyTorch and TensorFlow'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "context = \"\"\"\n",
    "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question = \"Which deep learning libraries back 🤗 Transformers?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bad65f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_context = \"\"\"\n",
    "🤗 Transformers: State of the Art NLP\n",
    "\n",
    "🤗 Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
    "question answering, summarization, translation, text generation and more in over 100 languages.\n",
    "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
    "\n",
    "🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
    "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
    "can be modified to enable quick research experiments.\n",
    "\n",
    "Why should I use transformers?\n",
    "\n",
    "1. Easy-to-use state-of-the-art models:\n",
    "  - High performance on NLU and NLG tasks.\n",
    "  - Low barrier to entry for educators and practitioners.\n",
    "  - Few user-facing abstractions with just three classes to learn.\n",
    "  - A unified API for using all our pretrained models.\n",
    "  - Lower compute costs, smaller carbon footprint:\n",
    "\n",
    "2. Researchers can share trained models instead of always retraining.\n",
    "  - Practitioners can reduce compute time and production costs.\n",
    "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
    "\n",
    "3. Choose the right framework for every part of a model's lifetime:\n",
    "  - Train state-of-the-art models in 3 lines of code.\n",
    "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
    "  - Seamlessly pick the right framework for training, evaluation and production.\n",
    "\n",
    "4. Easily customize a model or an example to your needs:\n",
    "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
    "  - Model internals are exposed as consistently as possible.\n",
    "  - Model files can be used independently of the library for quick experiments.\n",
    "\n",
    "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4c492e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9714912176132202,\n",
       " 'start': 1892,\n",
       " 'end': 1919,\n",
       " 'answer': 'Jax, PyTorch and TensorFlow'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question=question,\n",
    "    context=long_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27cd77",
   "metadata": {},
   "source": [
    "### Explanation - Question Answering <a class=\"anchor\" id=\"qa_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851471e4",
   "metadata": {},
   "source": [
    "This is a model which finds the answer to questions in given context. The question-answering pipeline is initialized to easily create the Question Answering pipeline, because it utilizes the DistilBERT model fine-tuned to SQuAD. After finding the possible answer with the best score, the offset mappings are used to find the corresponding answer in the context. When the context is very long, it might get truncated by the tokenizer. Then the most likely answer will be selected for each feature and the final answer is the one with the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c940f",
   "metadata": {},
   "source": [
    "In the part of implementations, there are two examples to be adapted. A short context was provided and then ask the question about the context was. The model analyzes the answer and gets its score briefly. After that, we take a look at a long context and set the same question. We can know that the same answer we got from the longer context as well, yet an answer from a pair of start and end positions are different from the short context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8b200",
   "metadata": {},
   "source": [
    "### 1-3. Load Summarization Pipeline  <a class=\"anchor\" id=\"summarization\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b6b52",
   "metadata": {},
   "source": [
    "Summarization (10 Points)\n",
    "\n",
    "Run a [Summarization](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b6808b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5e237e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cd59902abf43b8a70f36221144a420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f07e4fdcaf4570958b1988d9d62684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24e703e6581400890220d50237c0564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0709e8090a8b40e088673eff34c63f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2436b76cb94db6a7fa8bafa7fe0bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d55cc6",
   "metadata": {},
   "source": [
    "#### Summarize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d09479d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\"\n",
    "You don’t always have to give your boss the finger\n",
    "Maybe it’s your first day on the job. Perhaps your manager just made an announcement. You’ve been asked to scan your fingerprint every time you clock in and out. Is that even allowed?\n",
    "From Hooters to Hyatt Hotels, employers tantalized by the promise of a futuristic, streamlined way to track workers’ attendance are starting to use time clock machines that fingerprint employees.\n",
    "Vendors like Kronos and Allied Time say that because the machines are tied to your biometric information — unique characteristics such as your face, fingerprints, how you talk, and even how you walk — they provide a higher level of workplace security and limit employees’ ability to commit “time theft” by punching in for one another.\n",
    "But the benefits for your boss may come at a cost to you — both your privacy and possibly your health.\n",
    "With the global outbreak of COVID-19, your personal health could be at risk when using frequently touched screens and fingerprint scanners. The Centers for Disease Control says that coronavirus can remain on surfaces for hours, so screens and scanners should be regularly disinfected with cleaning spray or wipes. And you should wash your hands for 20 seconds or use alcohol-based hand sanitizer immediately after using one.\n",
    "In addition to these health concerns, critics argue that biometric devices pose massive personal security issues, exposing workers to potential identity theft and subjecting them to possible surveillance from corporations and law enforcement.\n",
    "In an amicus brief in a case before a federal court of appeals, a group of privacy advocates, including the ACLU and the EFF, wrote that “the immutability of biometric information” puts people “at risk of irreparable harm in the form of identity theft and/or tracking.”\n",
    "“You can get a new phone, you can change your password, you can even change your Social Security number; you can’t change your face,” said Kade Crockford, the Technology for Liberty program director at ACLU of Massachusetts.\n",
    "Companies facing legal action over their use of the machines range from fast food joints like McDonald’s and Wendy’s, to hotel chains like Marriott and Hyatt, to airlines like United and Southwest.\n",
    "In some cases, the companies have countered in the lawsuits that their employees’ union agreement allows the use of the machines: “Southwest and United contend that the plaintiffs’ unions have consented — either expressly or through the collective bargaining agreements’ management-rights clauses — and that any required notice has been provided to the unions,” the court’s opinion states.\n",
    "Other companies have not responded to requests for comment or have said they cannot comment on active litigation.\n",
    "Privacy and labor laws have lagged behind the shifts in the American workplace. But in some places, you have the right to refuse and even sue.\n",
    "\n",
    "Biometric Privacy Laws\n",
    "As the collection and use of biometrics has exploded, lawmakers in three states have responded by passing laws restricting its deployment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3958f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61a2615e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Employers are starting to use time clock machines that fingerprint employees . The machines are tied to your unique characteristics such as your face, fingerprints, how you talk, and even how you walk . The Centers for Disease Control says that coronavirus can remain on surfaces for hours .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8f72f",
   "metadata": {},
   "source": [
    "### Explanation - Summarization <a class=\"anchor\" id=\"sm_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b007b44",
   "metadata": {},
   "source": [
    "Summarization model is the task of summarizing a document or an article into a shorter text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd0937",
   "metadata": {},
   "source": [
    "There are two types of Text Summarization, one is Extractive Type and another one is Abstractive Type. Extractive summarization takes the original text and extracts information that is identical to it. In other words, rather than providing a unique summary based on the full content, it will rate each sentence in the document against all others, based on how well each line explains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c3b20",
   "metadata": {},
   "source": [
    "Hugging Face Transformer falls under abstractive type text summarization technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b536fd",
   "metadata": {},
   "source": [
    "From the result, the given article was summarized and we can see that it summarized by the requirements, such as max_length=130, min length=30. It provides a unique summary based on the full content and can get good scores even when pre-training with a very small sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10c8d6",
   "metadata": {},
   "source": [
    "### 1-4. Load Text Classification Pipeline   <a class=\"anchor\" id=\"text_classification \"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8357e",
   "metadata": {},
   "source": [
    "Text Classification (10 Points)\n",
    "\n",
    "Run a [Text Classification](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a080e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59420d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a657603f411541a58a55df888cf1e495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c151ccce68e4c80834054c4c5b65f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940ff8b0d022444b89202adc2656ad30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bbaab8ca1f40ed9eab23374a025484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a556c20d6a40e091a5c0e720ce757f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd4cf92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier(\"I love using transformers. The best part is wide range of support and its easy to use\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf644e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'sadness', 'score': 0.000679271062836051}, {'label': 'joy', 'score': 0.9959298968315125}, {'label': 'love', 'score': 0.0009452462545596063}, {'label': 'anger', 'score': 0.001805522944778204}, {'label': 'fear', 'score': 0.0004111044108867645}, {'label': 'surprise', 'score': 0.00022885717044118792}]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75758eeb",
   "metadata": {},
   "source": [
    "### Explanation - Text Classification <a class=\"anchor\" id=\"tc_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8258f",
   "metadata": {},
   "source": [
    "This model is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. The model was fine-tuned and evaluated on datasets from diverse text sources to enhance generalization across different types of texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e4b5a",
   "metadata": {},
   "source": [
    "In this model, I only use a small text to test the classifier and we got its sentiment analysis and accuracy scores of different emotional texts. The above example is a good example of positive emotions. We can see its keywords about joy, so this prediction is very accurate and precise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf8ae2",
   "metadata": {},
   "source": [
    "### 1-5. Load Text Generation Pipeline   <a class=\"anchor\" id=\"text_generation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02cbc00",
   "metadata": {},
   "source": [
    "Text Generation (10 Points)\n",
    "\n",
    "Run a [Text Generation](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5453157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61e0b509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6da5c689004acca78b7e3358400c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b6048779ab4c3f84da06786c312bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3015abe672e646dbbbc67d1ddf601b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a108633adf44333be3c702a067bc672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c0276e36544394a5616a427ee8236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "87696659",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a4d981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a graduate student in Northeastern University, having moved to Boston to spend summer after being admitted to Harvard. My thesis is my passion\"},\n",
       " {'generated_text': \"Hello, I'm a graduate student in Northeastern University, so I need a full-time internship with an existing college so that my students may not\"},\n",
       " {'generated_text': \"Hello, I'm a graduate student in Northeastern University, and had a few years as a professor there, but I'm not doing anything in graduate\"},\n",
       " {'generated_text': \"Hello, I'm a graduate student in Northeastern University, and I'm looking for a job. Would an applicant have a high-interest, high\"},\n",
       " {'generated_text': \"Hello, I'm a graduate student in Northeastern University, a Ph.D. Candidate in Economics and a J.D. candidate in Economics and\"}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Hello, I'm a graduate student in Northeastern University,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb0dd5",
   "metadata": {},
   "source": [
    "### Explanation - Text Generation <a class=\"anchor\" id=\"tg_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564026d",
   "metadata": {},
   "source": [
    "It pretrained model on English language using a causal language modeling (CLM) objective. GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences. The inputs are sequences of continuous text of a certain length and the targets are the same sequence, shifted one token (word or piece of word) to the right. The model uses internally a mask-mechanism to make sure the predictions for the token i only uses the inputs from 1 to i but not the future tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e0821",
   "metadata": {},
   "source": [
    "This way, the model learns an inner representation of the English language that can then be used to extract features useful for downstream tasks. The model is best at what it was pretrained for however, which is generating texts from a prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0a246",
   "metadata": {},
   "source": [
    "The generator generates several possible partial sentences according to its maximum length. We can know that the content it generates is related and mostly reasonable, but try to think about the logic of some sentence contexts. The logic may be wrong or contradictory. Therefore, this model needs more training or tuning to achieve better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda8fc2",
   "metadata": {},
   "source": [
    "### 1-6. Load Text2Text Generation Pipeline  <a class=\"anchor\" id=\"text2text_generation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751f44e",
   "metadata": {},
   "source": [
    "Text2Text Generation (10 Points)\n",
    "\n",
    "Run a [Text2Text](https://huggingface.co/models?pipeline_tag=text2text-generation&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e47d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82bd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_text = \"मुझे बोस्टन में रहना पसंद है।\"\n",
    "chinese_text = \"我喜歡住在波士頓。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7122a364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/shu-ya/opt/anaconda3/lib/python3.8/site-packages (0.1.96)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d04339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d67d2752d234c99832af95f34e8e44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.54M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f0e8714f204b149399e56b3749b80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cca0d48962e4452b7dd3f46c391325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/272 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29123bfa61ed4611ac5a5d67c8e2bffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45287a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['J’aime rester à Boston.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# translate Hindi to French\n",
    "tokenizer.src_lang = \"hi\"\n",
    "encoded_hi = tokenizer(hi_text, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(\"fr\"))\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2ac282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to live in Boston.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# translate Chinese to English\n",
    "tokenizer.src_lang = \"zh\"\n",
    "encoded_zh = tokenizer(chinese_text, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5979f818",
   "metadata": {},
   "source": [
    "### Explanation - Text2Text Generation <a class=\"anchor\" id=\"t2t_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc7bc2",
   "metadata": {},
   "source": [
    "M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. The model that can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token. To force the target language id as the first generated token, pass the forced_bos_token_id parameter to the generate method. M2M100Tokenizer depends on sentencepiece, so we install it before running the example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f872a",
   "metadata": {},
   "source": [
    "At the first, I define a sentence in 2 kind of languages - Hindi and Traditional Chinese. The sentence we set means 'I like to live in Boston.' In tokenizer.get_lang_id(\"fr\"), which means the language you want to transfer, so you can set any languages which are provided by. After that, we can see if it works or not. We transfer Hindi to French, then Traditional Chinese to English. After checking, it works well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae233d",
   "metadata": {},
   "source": [
    "### 1-7. Load Token Classification Pipeline  <a class=\"anchor\" id=\"token_classification\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7070d4e",
   "metadata": {},
   "source": [
    "Token Classification (10 Points)\n",
    "\n",
    "Run a [Token Classification](https://huggingface.co/models?pipeline_tag=token-classification&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befe4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8d7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d0a2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a19c671d884cfe99526575e1809f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2334ddc6a28046968977500ba9ce9220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a0e2c5f3014e4cac5eff88ecd7ef32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02387d51d920493d8fc4649d8726ac87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febb970fdb9b40c59f678e3f991d6ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0912e843b3c49aab52d761798567a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0430cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"My name is Julia and I live in Boston\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5309d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results = nlp(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b771795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.99860495, 'index': 4, 'word': 'Julia', 'start': 11, 'end': 16}, {'entity': 'B-LOC', 'score': 0.99624014, 'index': 9, 'word': 'Boston', 'start': 31, 'end': 37}]\n"
     ]
    }
   ],
   "source": [
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52fc76",
   "metadata": {},
   "source": [
    "### Explanation - Token Classification <a class=\"anchor\" id=\"tkc_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389638f",
   "metadata": {},
   "source": [
    "bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57d429",
   "metadata": {},
   "source": [
    "In the example, the simple sentence is defined and we get the result about each key token. We know that there are two key components which are Julia and Boston (Name and Location). The result print these tokens and their accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c1473",
   "metadata": {},
   "source": [
    "### 1-8. Load Translation Pipeline  <a class=\"anchor\" id=\"translation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299e216",
   "metadata": {},
   "source": [
    "Translation (10 Points)\n",
    "\n",
    "Run a [Translation](https://huggingface.co/models?pipeline_tag=translation&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04de264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3379f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base (https://huggingface.co/t5-base)\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation_en_to_de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c207d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Hugging Face ist ein Technologieunternehmen mit Sitz in New York und Paris.'}]\n"
     ]
    }
   ],
   "source": [
    "print(translator(\"Hugging Face is a technology company based in New York and Paris\", max_length=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6d939",
   "metadata": {},
   "source": [
    "### Explanation - Translation <a class=\"anchor\" id=\"trans_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a5b53",
   "metadata": {},
   "source": [
    "Translation is the task of translating a text from one language to another. We try to use an example of a translation dataset is the WMT English to German dataset, which has sentences in English as the input data and the corresponding sentences in German as the target data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67166106",
   "metadata": {},
   "source": [
    "The translator pipeline is different from the pipeline of the Text2Text generator, but in general, they all can do translation between different languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42e4a5",
   "metadata": {},
   "source": [
    "In the translator pipeline, we directly specify a specific language conversion in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355e874",
   "metadata": {},
   "source": [
    "### 1-9. Load Zero-Shot Classification Pipeline  <a class=\"anchor\" id=\"zero-shot_classification\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d9d81",
   "metadata": {},
   "source": [
    "Zero-Shot Classification (10 Points)\n",
    "\n",
    "Run a [Zero-Shot](https://huggingface.co/models?pipeline_tag=zero-shot-classification&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a7e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9b25c894c342a19d25796b4d57a9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87987550b4eb478c88a22978841e667f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022051872ff1418990eff5c080e4ea28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4303735e33894c01bb9af0106687a4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e1a56b552546f4bb139a759b357dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2b4d85b2f5433487271e4e39d8ed1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "439685de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `multi_class` argument has been deprecated and renamed to `multi_label`. `multi_class` will be removed in a future version of Transformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'exploration', 'dancing', 'cooking'],\n",
       " 'scores': [0.994511067867279,\n",
       "  0.9383883476257324,\n",
       "  0.00570622319355607,\n",
       "  0.0018192946445196867]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing', 'exploration']\n",
    "classifier(sequence_to_classify, candidate_labels, multi_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023176f",
   "metadata": {},
   "source": [
    "### Explanation - Zero-Shot Classification <a class=\"anchor\" id=\"zs_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013881b0",
   "metadata": {},
   "source": [
    "It is a method for using pre-trained NLI models as a ready-made zero-shot sequence classifiers. The method works by posing the sequence to be classified as the NLI premise and to construct a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f4adbf",
   "metadata": {},
   "source": [
    "For the sequence classification, we set the candidate labels and test which category it belongs to. After classifying, and we can understand what kind of category it is, and its results. The better score, the closer it is to that category, and the lower score, the less relevant it is to that category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3c1b9",
   "metadata": {},
   "source": [
    "### 1-10. Load Sentence Similarity Pipeline  <a class=\"anchor\" id=\"sentence_similarity\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cfa76",
   "metadata": {},
   "source": [
    "Sentence Similarity (10 Points)\n",
    "\n",
    "Run a [Sentence Similarity](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads) language model. Explain the theory behind your model, and run it.  Analyze how well you think it worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1846b113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8657d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81148b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9452b62ce4aa40c1a9d9264c32a9388a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97c558987b94c41b0b86c65a5bae3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adeb099db9f4e2fa66ad6dbb6340e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476c398d4ffa444cb18af3432737e63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4e3f4182ca4bf38cf766cafb4219c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc815bd274144f7b2319ff1498c14c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ecc61563354e94895b29a00fadc2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524a7abeb30a4f5bb71fbd4e4eac526d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1458b3744bca4c37abef390c68276a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f163e26a238e4456a7e7dc58e65112c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c72a55fed64cb7af52bd99a021c78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f44afeaf9054ae28f1dee317bffa52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa2e3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \\\n",
    "    ['Nothing much to say as it is a macbook. the M1 processor works like a charm', 'Amazing laptop, super performance with M1, its blazing fast',\n",
    "     'Working very slow and takes 15-20 minutes to start thus not worth for money',\n",
    "     'This is not a good laptop. It is very slow. It is taking 20 minutes to start'\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f7a0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a1a2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Nothing much to say as it is a macbook. the M1 processor works like a charm\n",
      "Embedding: [-2.46488184e-01 -2.08190918e-01 -1.11375190e-01 -1.02354307e-02\n",
      " -1.57813579e-01 -3.62280786e-01 -4.32110488e-01  9.86033026e-03\n",
      " -1.07506171e-01 -2.81675994e-01  1.49234027e-01  5.82048893e-02\n",
      " -4.16482836e-01 -3.29557598e-01  1.99979141e-01 -2.30781794e-01\n",
      "  4.69206721e-01 -3.71777952e-01  1.01849034e-01  3.07776809e-01\n",
      " -1.57086685e-01 -2.26009130e-01  1.97037272e-02  5.11454344e-02\n",
      " -4.27461788e-02  5.73057175e-01  6.20062649e-01  6.87860847e-01\n",
      " -2.13596582e-01 -2.89904028e-01 -1.45346090e-01  3.32339764e-01\n",
      "  1.22200176e-01  9.80937034e-02 -1.61603801e-02  3.91541533e-02\n",
      "  3.21472287e-01 -3.11650872e-01 -4.86470520e-01 -6.87191308e-01\n",
      " -2.24827200e-01  6.89012110e-01  5.74313819e-01  5.49121380e-01\n",
      "  7.78109014e-01  5.74669018e-02 -2.31808618e-01 -2.95517266e-01\n",
      "  6.50321543e-02 -1.25565469e-01 -2.27927536e-01 -1.22406743e-01\n",
      "  1.90444648e-01 -8.23577195e-02 -9.82053056e-02  6.47901177e-01\n",
      "  1.23948932e-01  3.83163303e-01  1.48437977e-01 -6.14493862e-02\n",
      " -3.05207610e-01 -8.68786685e-03 -1.40873298e-01 -1.40465230e-01\n",
      "  4.29827213e-01  8.93069804e-02 -1.35677367e-01 -2.08279639e-01\n",
      " -2.27474764e-01 -8.52710605e-02  8.19673687e-02 -6.73312068e-01\n",
      " -1.61140949e-01  4.90471423e-01  7.37962872e-02  2.08803609e-01\n",
      "  2.37046480e-01 -6.83669746e-01 -3.87781143e-01  4.55310434e-01\n",
      " -2.14157552e-01 -5.62347770e-02 -2.26153016e-01 -4.41390462e-02\n",
      "  6.82321727e-01  5.47628030e-02  2.50081062e-01 -5.51758781e-02\n",
      " -2.68558264e-01 -2.89360881e-01 -2.28142262e-01  4.08420324e-01\n",
      " -4.37436640e-01 -2.49038488e-01  4.07541901e-01  1.94485188e-01\n",
      "  3.34131032e-01 -2.80487508e-01 -6.10120118e-01  1.14628337e-01\n",
      "  1.63975880e-01 -2.78497785e-02 -7.73105472e-02  2.23959729e-01\n",
      " -2.52519876e-01 -2.27813244e-01 -7.80487880e-02  8.61240700e-02\n",
      "  1.69020414e-01 -3.61163378e-01  2.55002886e-01  3.02709788e-01\n",
      " -3.65841776e-01 -3.87703367e-02  3.87355387e-01 -5.86239159e-01\n",
      " -6.22344613e-01  2.10171774e-01  5.81831455e-01  4.77834761e-01\n",
      " -4.42540832e-02 -2.05133995e-03 -3.14049274e-01 -2.71618068e-01\n",
      " -1.19104184e-01 -1.36912391e-01 -8.19682330e-02  1.57347575e-01\n",
      " -7.85190165e-01 -2.78751701e-01 -1.15664780e-01 -2.79541194e-01\n",
      "  4.77322400e-01 -3.72845749e-03  2.55294383e-01  5.43030381e-01\n",
      "  3.47352862e-01 -5.69700226e-02 -2.79344797e-01 -3.42559487e-01\n",
      " -3.80247176e-01  5.32449841e-01  2.78395951e-01 -3.89061779e-01\n",
      " -7.84162208e-02  2.70510763e-01 -2.81563103e-01 -1.52801871e-01\n",
      "  1.03967443e-01  6.64727539e-02 -7.46313184e-02 -3.96352619e-01\n",
      "  4.38394547e-01  2.36952826e-01  1.86562300e-01  2.55675018e-01\n",
      "  2.31781438e-01  3.44285786e-01 -5.90732582e-02  7.66271874e-02\n",
      " -2.02850193e-01 -3.15609396e-01 -1.61887839e-01  5.06265238e-02\n",
      " -2.49907821e-01 -2.86354959e-01  3.47450793e-01  2.10432574e-01\n",
      " -1.17211148e-01  4.72383022e-01 -7.76035666e-01 -3.32149178e-01\n",
      "  6.82657436e-02  2.22441390e-01 -3.41026932e-01 -1.85946375e-01\n",
      "  2.55987585e-01 -6.21812344e-02 -4.81403589e-01 -3.85317445e-01\n",
      "  4.18180287e-01 -1.08209983e-01  3.65533531e-01 -2.11670212e-02\n",
      " -1.44074053e-01  3.88100624e-01  5.22860885e-01  9.25795138e-02\n",
      " -1.20045565e-01 -5.13739474e-02 -1.93763465e-01  4.72919375e-01\n",
      "  3.07540625e-01  4.80337471e-01  2.26435989e-01 -6.97913393e-02\n",
      " -5.14828190e-02 -1.78700060e-01 -5.26170313e-01 -1.78508490e-01\n",
      " -2.66656935e-01 -2.48447269e-01  7.17989802e-02 -1.74628258e-01\n",
      " -2.77464509e-01 -1.48627579e-01 -1.94779739e-01  1.67227298e-01\n",
      " -5.52225769e-01  3.61684918e-01  6.53958544e-02 -2.44429633e-01\n",
      "  3.76631171e-01  8.96408856e-01  2.02335745e-01  1.70935541e-01\n",
      "  7.65195563e-02 -1.48776174e-01  1.96211711e-01 -3.38637948e-01\n",
      " -1.72130629e-01 -1.44894198e-01 -4.16554272e-01 -1.45255342e-01\n",
      "  2.73052957e-02 -7.00209260e-01  7.06723258e-02  5.46822190e-01\n",
      " -1.27444297e-01 -9.26177949e-02  1.85891479e-01 -3.02582920e-01\n",
      "  4.44483049e-02 -8.39183182e-02 -1.08955458e-01  2.54898787e-01\n",
      " -4.04558271e-01 -2.36516476e-01  1.71027794e-01  1.69051532e-02\n",
      " -2.64745295e-01  1.14177346e-01  2.63352215e-01  1.95481569e-01\n",
      "  4.86113608e-01 -1.95489645e-01  1.11096185e-02 -2.80850559e-01\n",
      "  5.24767280e-01 -1.34779125e-01 -4.02680576e-01  3.27131927e-01\n",
      " -1.48453921e-01 -6.44753501e-02 -8.82075876e-02  5.13726532e-01\n",
      " -6.80605620e-02  5.62982671e-02 -2.32965760e-02  2.90088564e-01\n",
      "  4.33481514e-01 -4.00861263e-01  2.46409863e-01  1.31376192e-01\n",
      " -2.65821368e-01  9.43876281e-02 -5.94293475e-01  3.12791020e-01\n",
      "  1.42809778e-01  1.07696973e-01  1.98907495e-01 -2.79842228e-01\n",
      "  5.17004371e-01 -4.74733353e-01  4.82005507e-01  3.76044929e-01\n",
      "  1.81119412e-01  3.99707168e-01 -3.15923780e-01 -2.35113055e-01\n",
      " -7.07388809e-03 -4.85590935e-01 -7.33641461e-02  2.31356785e-01\n",
      "  2.49163106e-01 -2.29652599e-01 -1.23785421e-01 -2.25285843e-01\n",
      " -6.33815899e-02  2.73684770e-01  3.57577622e-01  4.50627714e-01\n",
      "  2.36023013e-02 -1.27017587e-01  1.71469569e-01 -5.34092598e-02\n",
      "  3.02835077e-01  3.09625179e-01 -1.32288158e-01 -6.60567135e-02\n",
      "  2.02520773e-01 -3.18697631e-01 -1.38892904e-01  1.41146258e-01\n",
      "  2.31443405e-01 -4.15373713e-01  4.97296592e-03  5.35547957e-02\n",
      " -8.45972449e-02 -1.98045466e-02 -1.48719445e-01  1.15703203e-01\n",
      " -3.58611971e-01  1.49187326e-01 -2.38604784e-01 -9.01122671e-03\n",
      " -1.80416554e-01  3.46368492e-01 -2.01613024e-01 -5.88773973e-02\n",
      " -3.49681824e-04  4.23551574e-02  1.42732784e-01  1.58484191e-01\n",
      " -3.38682830e-01  2.45882403e-02 -2.43089125e-01 -5.80854535e-01\n",
      "  5.11844933e-01 -1.69687897e-01  5.03526092e-01 -9.25553665e-02\n",
      " -4.78043467e-01  1.22797325e-01 -8.73459801e-02  3.83806467e-01\n",
      " -7.10404059e-03 -2.74322599e-01 -1.94406673e-01  1.15697440e-02\n",
      "  1.73167124e-01  2.23130539e-01  2.81979233e-01 -1.66836202e-01\n",
      "  1.60558134e-01 -6.60090009e-03 -1.95690691e-01  7.85553455e-01\n",
      "  9.60803255e-02 -2.32173488e-01 -3.87719452e-01  2.04674453e-01\n",
      "  3.77647430e-01 -1.40849855e-02  2.62793954e-02 -2.48107582e-01\n",
      "  2.11698487e-01  4.76623714e-01  5.59090912e-01 -2.83194959e-01\n",
      "  1.59329653e-01 -3.63424629e-01 -7.88410544e-01  2.51384914e-01\n",
      " -1.36474520e-01  2.83862144e-01 -2.12193727e-01 -2.90451050e-01\n",
      " -6.26023889e-01 -2.16540173e-02  6.90240204e-01 -3.10675744e-02\n",
      "  2.03397468e-01  2.62972772e-01 -7.28578260e-03 -2.80724056e-02\n",
      " -2.85772026e-01 -2.91979667e-02 -2.65527636e-01  1.61719084e-01\n",
      "  8.58678699e-01 -2.20958874e-01  3.70500892e-01  8.76941234e-02]\n",
      "\n",
      "Sentence: Amazing laptop, super performance with M1, its blazing fast\n",
      "Embedding: [-0.21137229  0.05266269 -0.49206924  0.02501145 -0.11647577 -0.34418643\n",
      " -0.4172939  -0.13115111 -0.32413152 -0.08769422  0.168444    0.4112183\n",
      " -0.07760988 -0.5189005  -0.13149242  0.26744223  0.52189547  0.00780811\n",
      "  0.2864501  -0.09345588 -0.3162027  -0.8923611  -0.06150824  0.11796525\n",
      " -0.04333772  0.45386738  0.4541944   0.5320136   0.13742901 -0.5313124\n",
      "  0.17678581 -0.27258527  0.01435896  0.14989851 -0.43948445  0.18552788\n",
      "  0.26000994 -0.60116905 -0.27279258 -0.59860575 -0.12684791  0.19818415\n",
      "  0.6081466   0.38662577  0.5006596   0.44066638 -0.45880476  0.41055775\n",
      " -0.07041018 -0.2868748  -0.57818997  0.1747465   0.32236835 -0.50749487\n",
      " -0.3681853   0.5321717   0.5204948  -0.08367535 -0.3998976  -0.35695982\n",
      "  0.14502572 -0.25135714  0.03537669 -0.23870334  0.43320927  0.09143494\n",
      "  0.20256965 -0.07569624 -0.25665382  0.69420826 -0.2988808  -0.13140485\n",
      " -0.68484646 -0.08982287 -0.31468445  0.31318954  0.2806698  -0.4243611\n",
      "  0.01461978  0.66039664  0.4006128  -0.41265565 -0.16408977 -0.72247654\n",
      "  1.0998884   0.13078983 -0.02378643 -0.06373828 -0.30251285 -1.0299407\n",
      " -0.01793411  0.0352001  -0.92968625  0.11046465  0.3882466   0.445561\n",
      "  0.9839038  -0.35958016 -0.20895782  0.23330685  0.49700335 -0.16745013\n",
      " -0.16100529 -0.03768996 -0.40880233 -0.20990722  0.2992      0.68777305\n",
      " -0.2322618  -0.27963033  0.17229877  0.42006758 -0.58474165  0.30532992\n",
      "  0.9596727   0.10679192 -1.0931108   0.74599195  0.00831859  0.14686987\n",
      " -0.3943597   0.14400057 -0.03777808 -0.45229757  0.27253574  0.01004861\n",
      "  0.6276623   0.12081135 -0.28097704 -0.5017236  -0.63539124  0.05904508\n",
      "  0.29326296 -0.01901605  0.10154072  0.6452013   0.45275688  0.13479868\n",
      " -0.50877416 -0.58132875 -0.201605    0.24735071  0.3052089  -0.5010393\n",
      "  0.09731989  0.3458543  -0.4149319  -0.30612814  0.77684397 -0.19865197\n",
      "  0.13292952  0.02722012  0.94485176  0.31947964  0.49586967  0.40985858\n",
      "  0.2271614   0.42166966  0.4618745  -0.19686627 -0.34844387 -0.14792594\n",
      " -0.01395647 -0.32507527 -0.20819592 -0.40523738  1.066622    0.5103573\n",
      " -0.42677763  0.6815849  -0.7288336  -0.2768686  -0.6906166   0.2758941\n",
      " -0.34941167  0.1285965  -0.00686341 -0.22075953 -0.6529244  -0.30798715\n",
      "  0.37774086  0.2093429   0.7932862   0.05863993  0.18387078  0.35983834\n",
      "  1.0402522   0.06954195  0.23346101 -0.5585689  -0.29287803  0.059537\n",
      " -0.04330584  0.05203078  0.3646445  -0.20622522  0.08822219 -0.1515751\n",
      " -0.06235872 -0.6352637   0.30960318 -0.48451772  0.14006442  0.3121376\n",
      "  0.16070166 -0.06268372 -0.51996946  0.21724963 -0.7156422   0.23777689\n",
      " -0.06341544 -0.2562183   0.5734468   1.0506434  -0.301436   -0.75501513\n",
      " -0.20812556 -0.17443639 -0.07155763  0.13522638  0.19287308 -0.27621505\n",
      " -0.71155864 -0.31639692  0.8005619  -0.0094975   0.38416785  0.59677404\n",
      "  0.35293964  0.20787312 -0.01598196 -0.01597744 -0.22581726 -0.09553671\n",
      "  0.1521301   0.29079914 -0.22455883 -0.23728743  0.14854982  0.12489606\n",
      "  0.2471579  -0.13462964  0.34605804  0.33211753  0.88124806 -0.5809302\n",
      " -0.03900327 -0.17126057  0.487478    0.13128725 -0.8496798   0.31751332\n",
      " -0.2226736  -0.3541597   0.3143037   0.6016225  -0.36910775 -0.25041318\n",
      "  0.04901893  0.37911162  0.3557405  -0.40835288  0.10574342  0.45542768\n",
      "  0.18458009  0.5159239  -0.30306906  0.61099726  0.7199873  -0.3507933\n",
      " -0.33443615 -0.17537563  0.06635098 -0.28622836  0.40989748 -0.1362221\n",
      "  0.01323236  0.4325212  -0.1022902  -0.29179528 -0.18694416  0.06507174\n",
      " -0.06669887 -0.17693765  0.08846737 -0.3792027  -0.18815634 -0.5669467\n",
      " -0.19004256  0.19583313  0.18719003  0.43428293 -0.032591   -0.07821164\n",
      " -0.9648483  -0.18628976  0.2026969   0.7526705  -0.29495445 -0.31474763\n",
      " -0.21594721 -0.02094275  0.6405605   0.1236349  -0.23335996  0.04035667\n",
      "  0.19459963 -0.6328607  -0.23321547 -0.08470647  0.15137056 -0.16229476\n",
      " -0.2870944  -0.7058175  -0.78634155  0.04470293  0.08373412  0.4288177\n",
      " -0.07424919 -0.3818657  -0.23325412  0.05134765 -0.01725489  0.54629904\n",
      " -0.27448493 -0.21830834 -0.49656534 -0.20075423  0.9458734  -0.26781967\n",
      "  0.967256   -0.63779444 -0.03695174  0.4346794   0.0333754   0.5860212\n",
      " -0.13539316 -0.1111366   0.04119148 -0.6705438   0.23195842  0.26268527\n",
      "  0.8040955  -0.5119517   0.60007864  0.11083723 -0.27759182  0.12697488\n",
      " -0.50620246 -0.13676025 -1.0261735  -0.11019688  0.46821678 -0.11112328\n",
      " -0.14053458  0.03015164 -0.15307324  0.391887    0.40993983  0.25717637\n",
      "  0.5371791  -0.15439299 -0.77042496  0.09080093 -0.16480368  0.09282572\n",
      " -0.06022946  0.0306632  -0.9840106  -0.1078762   0.26298884 -0.24186209\n",
      "  0.31863424  0.6522592   0.21906716 -0.394794   -0.1658283   0.04831231\n",
      "  0.10488293  0.3433828   1.3990648  -1.09073    -0.2844268  -0.12959746]\n",
      "\n",
      "Sentence: Working very slow and takes 15-20 minutes to start thus not worth for money\n",
      "Embedding: [ 8.83896723e-02 -6.40980303e-02  9.03919339e-02 -1.30770013e-01\n",
      "  1.99408367e-01 -3.85428011e-01 -2.16855586e-01  2.82200396e-01\n",
      " -5.06264806e-01 -2.59726495e-01 -1.64980710e-01  4.86857533e-01\n",
      " -3.66923176e-02 -1.89703088e-02 -2.34226167e-01 -1.13494873e-01\n",
      "  5.35487890e-01 -2.69917369e-01  2.10668817e-01 -1.20133072e-01\n",
      " -3.31089348e-01 -3.94984215e-01  1.79761097e-01  2.49665096e-01\n",
      "  2.47688293e-01  3.93257588e-01  1.25678837e-01 -3.01596185e-04\n",
      "  3.11506152e-01  6.50561377e-02 -1.81423485e-01 -2.95919687e-01\n",
      "  1.68042317e-01 -1.39894992e-01  3.25412422e-01  3.18607271e-01\n",
      " -2.19140261e-01 -4.96173427e-02  1.57282352e-01  1.41083688e-01\n",
      "  4.23445553e-02 -8.88379961e-02 -6.81599900e-02  2.68412620e-01\n",
      " -2.40756109e-01  8.75649508e-03  3.53648871e-01  9.89322066e-02\n",
      " -1.79900706e-01 -3.64389718e-01 -2.48048946e-01  1.61186457e-01\n",
      "  3.16122770e-01 -3.41308773e-01 -4.64873277e-02 -1.13282546e-01\n",
      " -8.93212669e-03  1.39537483e-01  1.72014490e-01 -2.17706919e-01\n",
      "  3.63311246e-02  3.47875729e-02 -2.33667478e-01 -5.13131738e-01\n",
      "  5.56663096e-01  2.26915359e-01 -1.60363913e-01 -3.13490838e-01\n",
      " -2.69811988e-01  4.92844522e-01  4.02658507e-02 -3.65658067e-02\n",
      " -7.56268024e-01  7.42500201e-02 -4.74372469e-02 -1.52073920e-01\n",
      "  2.07954630e-01 -3.87534350e-02  3.26478481e-02  6.95340149e-03\n",
      " -5.27901411e-01 -2.33424559e-01 -1.99803896e-02  4.45340633e-01\n",
      " -3.61545086e-01 -2.91781723e-01  6.26328826e-01  3.44253629e-01\n",
      "  8.06713820e-01 -3.19578677e-01  2.26702690e-01  4.81291711e-01\n",
      " -7.67196059e-01  2.20958471e-01 -2.20699683e-02  1.15621366e-01\n",
      " -1.11500109e-02  7.96432257e-01 -4.19786632e-01  2.11797774e-01\n",
      "  6.43044338e-02  5.34209311e-01 -4.09261137e-01 -2.89293736e-01\n",
      "  6.09458946e-02 -2.31632635e-01  9.76720825e-02  3.59260678e-01\n",
      " -3.63256708e-02  2.47798070e-01  3.24272752e-01  3.70144099e-01\n",
      " -2.66294599e-01  4.73718286e-01  4.11088020e-02  6.43921316e-01\n",
      " -6.05130255e-01  4.56739515e-02 -2.47561902e-01  3.26677144e-01\n",
      "  3.85852426e-01  2.22039059e-01 -2.36600503e-01 -3.36528271e-01\n",
      " -5.38662851e-01 -4.95229185e-01  3.21136475e-01  8.92841816e-02\n",
      " -2.57646441e-01  1.16582073e-01 -1.50800645e-02 -1.65517494e-01\n",
      " -1.25519633e-01 -2.72930592e-01  1.38438523e-01  3.34005177e-01\n",
      "  2.09014356e-01  2.07355440e-01  5.23589998e-02 -5.38774393e-02\n",
      " -3.19139808e-01  4.63853359e-01 -1.11994997e-01 -1.07343115e-01\n",
      "  5.80650687e-01 -4.32582110e-01  6.55690134e-02  1.59948781e-01\n",
      "  3.52064967e-01 -1.07694614e+00 -1.33449882e-01 -1.47678465e-01\n",
      " -6.60942718e-02 -5.38454473e-01  2.27432564e-01 -1.09707385e-01\n",
      "  4.46393132e-01 -9.83404443e-02 -3.58008385e-01 -1.04226090e-01\n",
      " -1.31289974e-01 -5.01747802e-02 -1.85636759e-01 -3.38353842e-01\n",
      "  1.44796632e-02  7.60062486e-02  4.19498593e-01 -1.57634228e-01\n",
      " -4.17814910e-01  6.79324329e-01 -3.45008244e-04 -4.97996062e-01\n",
      "  7.77974799e-02  4.61661369e-02  4.13749456e-01  3.54624063e-01\n",
      " -6.84643328e-01  1.60839409e-01 -1.00647554e-01  1.37289718e-01\n",
      "  6.07705116e-01  3.44572634e-01 -5.28837204e-01 -2.37151654e-03\n",
      "  5.41703582e-01 -2.34685689e-01 -2.19937459e-01  3.35537016e-01\n",
      " -5.33868745e-02  1.40999788e-02 -5.51719010e-01  3.63325745e-01\n",
      " -2.06332549e-01  3.65408629e-01 -4.82728332e-02  2.54148215e-01\n",
      "  2.43156493e-01 -2.75915742e-01  9.43100974e-02  3.14764917e-01\n",
      "  2.28662893e-01 -7.52664059e-02  1.27969846e-01 -3.10130298e-01\n",
      "  1.42425373e-01 -7.15911984e-02 -4.21705157e-01  5.41858487e-02\n",
      "  7.21478879e-01 -6.55448914e-01 -2.81163037e-01 -4.43792552e-01\n",
      "  5.23985922e-01  2.17463091e-01  2.82423437e-01 -2.80061871e-01\n",
      "  3.55375141e-01  5.83084375e-02 -1.23420984e-01  2.83173658e-02\n",
      " -1.22532882e-01  2.36250401e-01 -1.16580091e-01 -2.53852665e-01\n",
      "  4.84504282e-01 -4.64284956e-01  2.31240302e-01  2.83227831e-01\n",
      "  5.00523865e-01  2.95824204e-02  1.29416093e-01 -1.07812844e-01\n",
      " -1.29924476e-01  3.12909335e-02 -1.65196791e-01  9.84033048e-02\n",
      " -8.41670111e-02 -6.42011315e-02  2.17126191e-01 -2.03010589e-01\n",
      "  3.88775319e-01  1.98989868e-01  3.02779794e-01 -2.78088778e-01\n",
      "  3.29667509e-01  5.38978279e-01 -4.66954112e-01 -2.57399201e-01\n",
      "  2.55754888e-01  3.11426103e-01 -5.27427554e-01  5.03364384e-01\n",
      " -9.95566607e-01  1.93454865e-02 -1.68346427e-02 -2.40587175e-01\n",
      " -1.79573253e-01  1.57396004e-01 -3.50219868e-02  8.08362290e-03\n",
      "  1.39370132e-02  2.37227939e-02  2.32357562e-01  3.76197904e-01\n",
      "  6.61555171e-01 -1.04732715e-01 -1.12108022e-01 -6.15651429e-01\n",
      " -2.96066198e-02 -2.87031025e-01 -3.12022120e-01 -8.02047074e-01\n",
      " -4.89940830e-02  6.30839244e-02  5.86903811e-01  7.49828219e-01\n",
      "  5.73699534e-01  5.79733014e-01 -3.70407254e-02  1.55307353e-01\n",
      " -2.50788093e-01 -3.00649628e-02 -6.41210973e-02  2.82655180e-01\n",
      " -1.82601854e-01 -3.06580663e-01 -1.56688422e-01 -1.15238734e-01\n",
      "  3.81414481e-02 -4.85554010e-01  7.19708391e-03  2.13900104e-01\n",
      "  2.64285445e-01 -1.01223588e-01 -3.58140469e-01  6.57293797e-01\n",
      " -1.22144014e-01  3.12577933e-01 -3.90715301e-01  1.07275195e-01\n",
      " -2.73553550e-01 -2.42026597e-01  5.52196912e-02 -4.56958979e-01\n",
      " -6.99783191e-02  2.88501177e-02 -1.07947789e-01 -2.37414703e-01\n",
      " -3.85276765e-01  7.21363902e-01 -2.99286991e-01  1.87460065e-01\n",
      "  1.91204771e-01  5.98236918e-02 -1.01543970e-01  1.22972488e-01\n",
      "  6.38173044e-01  5.65205812e-01 -5.24227619e-01 -9.98929217e-02\n",
      "  8.25867951e-02 -1.69721082e-01  8.77250079e-03  2.89787978e-01\n",
      " -1.42848551e-01 -2.98002064e-01 -3.44728142e-01 -3.80891979e-01\n",
      "  2.83598512e-01 -4.49655801e-02  7.43668914e-01 -6.14235640e-01\n",
      "  7.44031966e-02  3.66262734e-01 -3.20701838e-01 -2.35655442e-01\n",
      "  1.47955358e-01 -1.47979677e-01 -2.81522930e-01 -3.81419063e-01\n",
      "  2.33772546e-01 -1.73533916e-01 -3.04085255e-01  3.55186135e-01\n",
      "  7.07417279e-02  5.74893542e-02  3.03241342e-01  6.80286109e-01\n",
      " -3.59328598e-01 -4.75985944e-01 -3.06027800e-01  2.49164611e-01\n",
      " -2.70114094e-02 -5.19783944e-02  2.12951563e-02 -4.09261614e-01\n",
      "  3.18138808e-01  3.09469581e-01 -4.55071986e-01  3.29365730e-01\n",
      " -1.81452021e-01 -1.02586553e-01 -2.47467831e-01 -4.34404463e-02\n",
      "  8.69531780e-02 -2.69422650e-01 -8.17492187e-01  1.09594308e-01\n",
      "  2.74938215e-02 -4.09950256e-01  5.52182555e-01  2.23082989e-01\n",
      "  2.06744358e-01 -2.91811943e-01  7.72832334e-01 -3.27998921e-02\n",
      " -2.15707913e-01  1.96117058e-01 -2.61738539e-01 -2.43911132e-01\n",
      "  2.88117439e-01 -1.91227853e-01 -3.39322120e-01  7.66546503e-02]\n",
      "\n",
      "Sentence: This is not a good laptop. It is very slow. It is taking 20 minutes to start\n",
      "Embedding: [-0.19062635 -0.10849251  0.19155991 -0.00514434  0.15453264 -0.10074399\n",
      " -0.7918812  -0.15743896  0.12534341  0.19267021 -0.02833016  0.46812758\n",
      " -0.15335388 -0.10758131 -0.36291534  0.2573685   0.43978953 -0.2880386\n",
      "  0.41561562 -0.00177073 -0.3629505  -0.2305274   0.18833393 -0.00981058\n",
      " -0.20025235  0.13402443  0.6845117   0.1407375   0.04637966 -0.09712583\n",
      " -0.02549835 -0.22938615  0.30624336 -0.2630447   0.09447033 -0.00600145\n",
      " -0.25490692 -0.41876897 -0.04189482 -0.31122312  0.02943991  0.39086074\n",
      "  0.24439657  0.41203198  0.07399721  0.30282578 -0.09999658  0.1138642\n",
      " -0.04606397 -0.12120954 -0.540962    0.09131559  0.1701968  -0.5285554\n",
      "  0.10894233 -0.02814596  0.37290102  0.30385166 -0.11367428 -0.25116235\n",
      "  0.29254493 -0.6307293   0.11720908 -0.34010786  0.30798453  0.11680115\n",
      "  0.495192   -0.29493326  0.01306369  0.06923196 -0.5549474  -0.08505698\n",
      " -0.5539605   0.40631935 -0.08244372 -0.3812386   0.1141414   0.10335992\n",
      "  0.15773475  0.21810296  0.01617714 -0.19397002 -0.090022   -0.33893797\n",
      "  0.04615794 -0.17871515  0.24823593  0.06194726 -0.23213053 -0.7776186\n",
      "  0.01094792  0.06127642 -0.26280776  0.17755774 -0.11637045  0.17009303\n",
      "  0.11547647  0.13644852 -0.3391071  -0.03829153  0.19904716  0.28892\n",
      " -0.4407634  -0.02498746 -0.4837312  -0.4500688   0.36845046  0.46810365\n",
      "  0.01818873  0.29668412  0.08693402  0.5366355  -0.33122334  0.50919205\n",
      "  0.38851434  0.51004153 -0.5423645   0.26801938  0.16867895  0.34318632\n",
      "  0.13778856 -0.17879231 -0.3831884  -0.7350856  -0.23904133 -0.44738466\n",
      "  0.06534965  0.05870224  0.01441614 -0.36521253 -0.56062907  0.00807031\n",
      "  0.2530606  -0.44415754  0.30166507  0.7266383   0.10495542 -0.24873048\n",
      " -0.09951373 -0.40790573 -0.51066667  0.5201593   0.06364881 -0.5862899\n",
      " -0.02267774 -0.01171776 -0.3349258  -0.04944342  0.44450057 -0.39871335\n",
      "  0.14813866 -0.11821447  0.4314491   0.13390307  0.4518008   0.1667021\n",
      "  0.35059106  0.09126625 -0.00740119 -0.16217671 -0.15895905 -0.282111\n",
      " -0.06537765 -0.15879111  0.03738196  0.0695868   0.4750034   0.1241609\n",
      " -0.23520096  0.6798775  -0.45422444 -0.31755543  0.2103898  -0.13843162\n",
      "  0.28086367  0.211247   -0.01069616  0.13945594 -0.48801056 -0.0019793\n",
      "  0.49925524  0.56924266  0.16655     0.11876726  0.26182467 -0.03234218\n",
      "  0.2827932   0.30378273  0.25165203 -0.308574   -0.70327824  0.29320213\n",
      "  0.25858387  0.46935108  0.15255728  0.18134414  0.33220944 -0.16502246\n",
      "  0.01003084 -0.15659495  0.05400658  0.15005678 -0.05997817  0.20548409\n",
      " -0.13845333  0.18222949 -0.57174957 -0.13763762 -0.00734484 -0.2153567\n",
      "  0.11374368 -0.29479203 -0.17451307  0.27244538 -0.183344   -0.17211826\n",
      " -0.09734754 -0.17557412 -0.10038718  0.38703772 -0.044045    0.33414024\n",
      " -0.12835984 -0.34635338  0.34910786 -0.4423306   0.07186142  0.4596588\n",
      "  0.465542   -0.10594419  0.10936737  0.44897342 -0.17750327 -0.17977038\n",
      " -0.23624048 -0.09115753 -0.3004249  -0.12929723  0.43798256  0.1771025\n",
      "  0.643903    0.05494974  0.14711376  0.06968348  0.34040886  0.6922018\n",
      " -0.34335265 -0.39455682  0.7960221   0.17267577 -0.12929708  0.3732426\n",
      " -0.8925121   0.21108477 -0.09489261 -0.41201305 -0.03923251  0.00266848\n",
      " -0.07994966  0.38227963  0.25706735 -0.2759398   0.30805925  0.5907787\n",
      "  0.5910594   0.25549886 -0.3588593  -0.26338568  0.31056646  0.10511318\n",
      " -0.37882417 -0.5346034  -0.04062396 -0.06563821  0.3888954   0.3406462\n",
      "  0.71797335  0.2986466   0.07242368 -0.20051965 -0.33200318  0.26878905\n",
      "  0.6368873   0.2368274  -0.04985352 -0.19813731 -0.12071278 -0.7283695\n",
      " -0.0854952  -0.07479183  0.21121347  0.459989    0.35314754 -0.17119426\n",
      " -0.8496229   0.37841618 -0.19962038  0.17683804 -0.00363961 -0.12819931\n",
      " -0.20231465 -0.26831463 -0.04919671 -0.35127854 -0.17622712  0.24254408\n",
      " -0.28726196 -0.41970503 -0.19439156  0.30205277 -0.1922203   0.22333822\n",
      " -0.11710323 -0.05820702 -0.6240047  -0.23294866  0.2968464   0.2840691\n",
      " -0.31325692 -0.2995765   0.23863213  0.09145208  0.05374362  0.62586117\n",
      " -0.26429304 -0.23104772 -0.43855578 -0.3621315   0.441525   -0.17734589\n",
      "  0.56682765 -0.41776848 -0.12560458  0.42575726 -0.5816385   0.36678013\n",
      " -0.21906458  0.01896022 -0.06055731 -0.7542461   0.3197896  -0.43370306\n",
      "  0.40076873 -0.06604048  0.2808967   0.36461174  0.13191298  0.06638328\n",
      " -0.06086155 -0.9505183  -1.0141449   0.27366105  0.00927957  0.15918817\n",
      "  0.05980524  0.26544318 -0.3093041   0.40447912  0.1791819   0.24268441\n",
      "  0.08582494  0.02862103 -0.26510593  0.11971005 -0.04679397  0.04741565\n",
      " -0.37326244  0.09481388 -0.4319626  -0.28545922  0.47190413 -0.08823749\n",
      "  0.13139997  0.47762153  0.5619725   0.11775238 -0.01169228 -0.07039844\n",
      " -0.22730663  0.30937782  0.36265236 -0.07472567 -0.20780618  0.05390412]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e2c9054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d004fdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8c71724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Nothing much to say as it is a macbook. the M1 processor works like a charm and Amazing laptop, super performance with M1, its blazing fast is 0.6136189103126526\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between {} and {} is {}'.format(sentences[0],\n",
    "       sentences[1],\n",
    "       cosine_similarity(sentence_embeddings[0].reshape(1, -1),\n",
    "       sentence_embeddings[1].reshape(1, -1))[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9654c01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Nothing much to say as it is a macbook. the M1 processor works like a charm and Working very slow and takes 15-20 minutes to start thus not worth for money is 0.20321230590343475\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between {} and {} is {}'.format(sentences[0],\n",
    "       sentences[2],\n",
    "       cosine_similarity(sentence_embeddings[0].reshape(1, -1),\n",
    "       sentence_embeddings[2].reshape(1, -1))[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3298fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Working very slow and takes 15-20 minutes to start thus not worth for money and This is not a good laptop. It is very slow. It is taking 20 minutes to start is 0.5791779160499573\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between {} and {} is {}'.format(sentences[2],\n",
    "       sentences[3],\n",
    "       cosine_similarity(sentence_embeddings[2].reshape(1, -1),\n",
    "       sentence_embeddings[3].reshape(1, -1))[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6e2c6",
   "metadata": {},
   "source": [
    "### Explanation - Sentence Similarity <a class=\"anchor\" id=\"ss_explanation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa3f53",
   "metadata": {},
   "source": [
    "We can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860b081",
   "metadata": {},
   "source": [
    "In our examples, we use the sentence_transformers model to compare different similarities. It compares each similarity between the sentence_embeddings, and we can get the higher similarity if they are much more similar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095df00",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afe14d27",
   "metadata": {},
   "source": [
    "Cited as:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e2aa7e4",
   "metadata": {},
   "source": [
    "@article{Hugging Face\n",
    "  title   = \"Hugging Face\",\n",
    "  author  = \"Chaumond, Julien\",\n",
    "  year    = \"2016\",\n",
    "  url     = \"https://huggingface.co/models\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b5d01da",
   "metadata": {},
   "source": [
    "@article{Youtube\n",
    "  title   = \"HuggingFace Crash Course - Sentiment Analysis, Model Hub, Fine Tuning\",\n",
    "  author  = \"Loeber, Patrick\",\n",
    "  year    = \"2021\",\n",
    "  url     = \"https://www.youtube.com/watch?v=GSt00_-0ncQ\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d9f91a3",
   "metadata": {},
   "source": [
    "@article{Youtube\n",
    "  title   = \"Text Classification Using BERT & Tensorflow | Deep Learning Tutorial 47)\",\n",
    "  author  = \"Codebasics\",\n",
    "  year    = \"2021\",\n",
    "  url     = \"https://www.youtube.com/watch?v=hOCDJyZ6quA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5457297a",
   "metadata": {},
   "source": [
    "@article{GitHub\n",
    "  title   = \"Hugging-Face-Transformers-Summarization)\",\n",
    "  author  = \"Renotte, Nicholas\",\n",
    "  year    = \"2021\",\n",
    "  url     = \"https://github.com/nicknochnack/Hugging-Face-Transformers-Summarization\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e919a0",
   "metadata": {},
   "source": [
    "# Copyright and Licensing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87075b70",
   "metadata": {},
   "source": [
    "BSD 3-Clause License\n",
    "\n",
    "Copyright (c) 2021, Shu-Ya Hsu\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this\n",
    "  list of conditions and the following disclaimer.\n",
    "\n",
    "* Redistributions in binary form must reproduce the above copyright notice,\n",
    "  this list of conditions and the following disclaimer in the documentation\n",
    "  and/or other materials provided with the distribution.\n",
    "\n",
    "* Neither the name of the copyright holder nor the names of its\n",
    "  contributors may be used to endorse or promote products derived from\n",
    "  this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df2e91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Hsu-Ya Hsu.\n",
    "# Distributed under the terms of the 3-Clause BSD License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03862ec7",
   "metadata": {},
   "source": [
    "You are free to use or adapt this notebook for any purpose you'd like. However, please respect the [Modified BSD License](https://jupyter.org/governance/projectlicense.html) that governs its use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32687585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
